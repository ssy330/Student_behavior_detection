# server.py
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

from pathlib import Path
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List

###############################################
# 0. ê¸°ë³¸ ì„¤ì •
###############################################

# âœ” í–‰ë™ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ (í•„ìˆ˜)
ACTION_STATE_PATH = r"C:\dev\cv\model\stgcn_onecyclelr.pth"

# âœ” ì§‘ì¤‘ë„ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ (ì§€ê¸ˆì€ ì—†ìŒ â†’ ë‚˜ì¤‘ì— ëª¨ë¸ ìƒê¸°ë©´ ê²½ë¡œë§Œ ë„£ê¸°)
# ì˜ˆ: r"C:\dev\cv\model\stgcn_focus.pth"
FOCUS_STATE_PATH: str | None = None

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# === í´ë˜ìŠ¤ ID â†’ í–‰ë™ ë¼ë²¨ ë§¤í•‘ (ì§ì ‘ ì±„ìš°ë©´ ë¨) ===
ACTION_ID_TO_LABEL = {
    0: "ë¬¼ ë§ˆì‹œê¸°",
    1: "ìŒì‹ ë¨¹ê¸°",
    2: "ì•‰ê¸°",
    3: "ì¼ì–´ë‚˜ê¸°",
    4: "ì½ê¸°",
    5: "ì“°ê¸°",
    6: "ì¢…ì´ ì°¢ê¸°",
    7: "ì „í™”í•˜ê¸°",
    8: "íœ´ëŒ€í° í•˜ê¸°",
    9: "í‚¤ë³´ë“œ ì¹˜ê¸°",
    10: "ì‹œê³„ í™•ì¸í•˜ê¸°",
    11: "ê¸°ì¹¨í•˜ê¸°",
}

# === ì§‘ì¤‘ë„ ID â†’ ë¼ë²¨ ë§¤í•‘ (ì˜ˆ: 0=ë‚®ìŒ, 1=ì¤‘ê°„, 2=ë†’ìŒ) ===
# ë‚˜ì¤‘ì— ì§‘ì¤‘ë„ ëª¨ë¸ í•™ìŠµí•˜ë©´ ì‹¤ì œ í´ë˜ìŠ¤ì— ë§ê²Œ ìˆ˜ì •
FOCUS_ID_TO_LABEL = {
    0: "ë‚®ìŒ",
    1: "ì¤‘ê°„",
    2: "ë†’ìŒ",
}


###############################################
# 1. ê·¸ë˜í”„ ê´€ë ¨ í•¨ìˆ˜ë“¤ (í•™ìŠµ ì½”ë“œ ê·¸ëŒ€ë¡œ)
###############################################

def get_edge():
    num_node = 25
    self_link = [(i, i) for i in range(num_node)]
    neighbor_1base = [
        (1, 2), (2, 21), (3, 21), (4, 3), (5, 21),
        (6, 5), (7, 6), (8, 7), (9, 21), (10, 9),
        (11, 10), (12, 11), (13, 1), (14, 13), (15, 14),
        (16, 15), (17, 1), (18, 17), (19, 18), (20, 19),
        (22, 23), (23, 8), (24, 25), (25, 12)
    ]
    neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_1base]
    edge = self_link + neighbor_link
    center = 21 - 1
    return edge, center


def get_hop_distance(num_node, edge, max_hop=1):
    A = np.zeros((num_node, num_node))
    for i, j in edge:
        A[j, i] = 1
        A[i, j] = 1

    hop_dis = np.zeros((num_node, num_node)) + np.inf
    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(max_hop + 1)]
    arrive_mat = (np.stack(transfer_mat) > 0)
    for d in range(max_hop, -1, -1):
        hop_dis[arrive_mat[d]] = d
    return hop_dis


def get_adjacency(hop_dis, center, num_node, max_hop, dilation):
    valid_hop = range(0, max_hop + 1, dilation)
    adjacency = np.zeros((num_node, num_node))
    for hop in valid_hop:
        adjacency[hop_dis == hop] = 1
    normalize_adjacency = adjacency
    A = []
    for hop in valid_hop:
        a_root = np.zeros((num_node, num_node))
        a_close = np.zeros((num_node, num_node))
        a_further = np.zeros((num_node, num_node))
        for i in range(num_node):
            for j in range(num_node):
                if hop_dis[j, i] == hop:
                    if hop_dis[j, center] == hop_dis[i, center]:
                        a_root[j, i] = normalize_adjacency[j, i]
                    elif hop_dis[j, center] > hop_dis[i, center]:
                        a_close[j, i] = normalize_adjacency[j, i]
                    else:
                        a_further[j, i] = normalize_adjacency[j, i]
        if hop == 0:
            A.append(a_root)
        else:
            A.append(a_root + a_close)
            A.append(a_further)
    A = np.stack(A)
    return A


num_node = 25
edge, center = get_edge()
hop_dis = get_hop_distance(num_node, edge, max_hop=1)
A_np = get_adjacency(hop_dis, center, num_node, max_hop=1, dilation=1)
A = torch.tensor(A_np, dtype=torch.float32, requires_grad=False)


###############################################
# 2. ST-GCN ëª¨ë¸ ì •ì˜ (í•™ìŠµ ì½”ë“œ ê·¸ëŒ€ë¡œ)
###############################################

class ConvTemporalGraphical(nn.Module):
    def __init__(
        self,
        in_channels,
        out_channels,
        kernel_size,
        t_kernel_size=1,
        t_stride=1,
        t_padding=0,
        t_dilation=1,
        bias=True
    ):
        super().__init__()
        self.kernel_size = kernel_size
        self.conv = nn.Conv2d(
            in_channels,
            out_channels * kernel_size,
            kernel_size=(t_kernel_size, 1),
            padding=(t_padding, 0),
            stride=(t_stride, 1),
            dilation=(t_dilation, 1),
            bias=bias
        )

    def forward(self, x, A):
        assert A.size(0) == self.kernel_size
        x = self.conv(x)
        n, kc, t, v = x.size()
        x = x.view(n, self.kernel_size, kc // self.kernel_size, t, v)
        x = torch.einsum("nkctv,kvw->nctw", (x, A))
        return x.contiguous(), A


class st_gcn(nn.Module):
    def __init__(
        self,
        in_channels,
        out_channels,
        kernel_size,
        stride=1,
        dropout=0,
        residual=True
    ):
        super().__init__()
        assert len(kernel_size) == 2
        assert kernel_size[0] % 2 == 1
        padding = ((kernel_size[0] - 1) // 2, 0)

        self.gcn = ConvTemporalGraphical(in_channels, out_channels, kernel_size[1])
        self.tcn = nn.Sequential(
            nn.GroupNorm(8, out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(
                out_channels,
                out_channels,
                (kernel_size[0], 1),
                (stride, 1),
                padding,
            ),
            nn.GroupNorm(8, out_channels),
            nn.Dropout(dropout, inplace=True),
        )

        if not residual:
            self.residual = lambda x: 0
        elif (in_channels == out_channels) and (stride == 1):
            self.residual = lambda x: x
        else:
            self.residual = nn.Sequential(
                nn.Conv2d(
                    in_channels,
                    out_channels,
                    kernel_size=1,
                    stride=(stride, 1),
                ),
                nn.BatchNorm2d(out_channels),
            )

        self.relu = nn.ReLU(inplace=True)

    def forward(self, x, A):
        res = self.residual(x)
        x, A = self.gcn(x, A)
        x = self.tcn(x) + res
        return self.relu(x), A


class Model(nn.Module):
    def __init__(self, in_channels, num_class, A, edge_importance_weighting, dropout):
        super().__init__()
        self.register_buffer("A", A)
        spatial_kernel_size = A.size(0)
        temporal_kernel_size = 9
        kernel_size = (temporal_kernel_size, spatial_kernel_size)
        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))
        channels = [64, 64, 64, 128, 128, 256]

        self.st_gcn_networks = nn.ModuleList(
            (
                st_gcn(in_channels, channels[0], kernel_size, 1, dropout=0.1, residual=False),
                st_gcn(channels[0], channels[1], kernel_size, 1, dropout=0.2),
                st_gcn(channels[1], channels[2], kernel_size, 1, dropout=0.3),
                st_gcn(channels[2], channels[3], kernel_size, 2, dropout=0.3),
                st_gcn(channels[3], channels[4], kernel_size, 2, dropout=0.3),
                st_gcn(channels[4], channels[5], kernel_size, 2, dropout=0.3),
            )
        )

        if edge_importance_weighting:
            self.edge_importance = nn.ParameterList(
                [nn.Parameter(torch.ones(self.A.size())) for _ in self.st_gcn_networks]
            )
        else:
            self.edge_importance = [1] * len(self.st_gcn_networks)

        last_channels = channels[-1]
        self.fcn = nn.Conv2d(last_channels, num_class, kernel_size=1)

    def forward(self, x):
        N, C, T, V, M = x.size()
        x = x.permute(0, 4, 3, 1, 2).contiguous()   # N,M,V,C,T
        x = x.view(N * M, V * C, T)
        x = self.data_bn(x)
        x = x.view(N, M, V, C, T)
        x = x.permute(0, 1, 3, 4, 2).contiguous()   # N,M,C,T,V
        x = x.view(N * M, C, T, V)

        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):
            x, _ = gcn(x, self.A * importance)

        x = F.avg_pool2d(x, x.size()[2:])
        x = x.view(N, M, -1, 1, 1).mean(dim=1)
        x = self.fcn(x)
        x = x.view(x.size(0), -1)
        return x


###############################################
# 3. ëª¨ë¸ ë¡œë“œ + ì¶”ë¡  ìœ í‹¸
###############################################

def load_stgcn_model(state_path: str, in_channels: int = 3, dropout: float = 0.2):
    checkpoint = torch.load(state_path, map_location=device)

    # checkpoint í¬ë§· ìœ ì—°í•˜ê²Œ ì²˜ë¦¬
    if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
        state_dict = checkpoint["model_state_dict"]
    else:
        state_dict = checkpoint

    fcn_weight = state_dict["fcn.weight"]
    num_class = fcn_weight.shape[0]
    print(f"[{state_path}] num_class detected: {num_class}")

    model = Model(
        in_channels=in_channels,
        num_class=num_class,
        A=A,
        edge_importance_weighting=True,
        dropout=dropout,
    ).to(device)
    model.load_state_dict(state_dict)
    model.eval()
    print(f"âœ… ST-GCN model loaded from: {state_path}")
    return model, num_class


# âœ” í–‰ë™ ëª¨ë¸ì€ í•­ìƒ ë¡œë“œ (í•„ìˆ˜)
if not Path(ACTION_STATE_PATH).exists():
    raise FileNotFoundError(f"Action model checkpoint not found: {ACTION_STATE_PATH}")

action_model, ACTION_NUM_CLASS = load_stgcn_model(ACTION_STATE_PATH)

# âœ” ì§‘ì¤‘ë„ ëª¨ë¸ì€ ì„ íƒì ìœ¼ë¡œ ë¡œë“œ (ì—†ìœ¼ë©´ None)
if FOCUS_STATE_PATH is not None and Path(FOCUS_STATE_PATH).exists():
    focus_model, FOCUS_NUM_CLASS = load_stgcn_model(FOCUS_STATE_PATH)
else:
    focus_model = None
    FOCUS_NUM_CLASS = 0
    print("âš  ì§‘ì¤‘ë„ ëª¨ë¸ ì—†ìŒ: /predict_focus ì—”ë“œí¬ì¸íŠ¸ëŠ” 503 ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")


def predict_action_single(skel_array: np.ndarray):
    """í–‰ë™ ëª¨ë¸ë¡œ ì˜ˆì¸¡"""
    x = torch.from_numpy(skel_array).float().unsqueeze(0).to(device)  # (1,C,T,V,M)
    with torch.no_grad():
        logits = action_model(x)
        probs = torch.softmax(logits, dim=1)
        pred_idx = int(torch.argmax(probs, dim=1).item())
        probs_np = probs.cpu().numpy()[0]
    return pred_idx, probs_np


def predict_focus_single(skel_array: np.ndarray):
    """ì§‘ì¤‘ë„ ëª¨ë¸ë¡œ ì˜ˆì¸¡ (ëª¨ë¸ì´ ìˆì„ ë•Œë§Œ ì‚¬ìš©)"""
    if focus_model is None:
        raise RuntimeError("Focus model is not loaded.")

    x = torch.from_numpy(skel_array).float().unsqueeze(0).to(device)  # (1,C,T,V,M)
    with torch.no_grad():
        logits = focus_model(x)
        probs = torch.softmax(logits, dim=1)
        pred_idx = int(torch.argmax(probs, dim=1).item())
        probs_np = probs.cpu().numpy()[0]
    return pred_idx, probs_np


###############################################
# 4. FastAPI ì„¤ì •
###############################################

app = FastAPI()

# CORS (Vite dev ì„œë²„ ë„ë©”ì¸ í—ˆìš©)
origins = [
    "http://localhost:5173",
    "http://127.0.0.1:5173",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ì…ë ¥: skeleton (C,T,V,M)
class SkeletonInput(BaseModel):
    skeleton: List[List[List[List[float]]]]  # 4D ë°°ì—´


class ActionPredictResponse(BaseModel):
    action_id: int
    action_label: str
    probs: List[float]


class FocusPredictResponse(BaseModel):
    focus_id: int
    focus_label: str
    probs: List[float]


# ğŸ‘‰ í”„ë¡ íŠ¸ì—ì„œ /predict_action ë˜ëŠ” /predict ë‘˜ ë‹¤ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ
@app.post("/predict_action", response_model=ActionPredictResponse)
@app.post("/predict", response_model=ActionPredictResponse)
def predict_action(input_data: SkeletonInput):
    """
    í–‰ë™ ì˜ˆì¸¡ ì—”ë“œí¬ì¸íŠ¸ (í–‰ë™ ëª¨ë¸ë§Œ ì‚¬ìš©)
    """
    skel_np = np.array(input_data.skeleton, dtype=np.float32)  # (C,T,V,M)
    pred_idx, probs = predict_action_single(skel_np)
    action_label = ACTION_ID_TO_LABEL.get(pred_idx, f"class_{pred_idx}")

    return ActionPredictResponse(
        action_id=pred_idx,
        action_label=action_label,
        probs=probs.tolist(),
    )


@app.post("/predict_focus", response_model=FocusPredictResponse)
def predict_focus(input_data: SkeletonInput):
    """
    ì§‘ì¤‘ë„ ì˜ˆì¸¡ ì—”ë“œí¬ì¸íŠ¸ (ì§‘ì¤‘ë„ ëª¨ë¸ì´ ìˆì„ ë•Œë§Œ ì •ìƒ ë™ì‘)
    """
    if focus_model is None:
        # í”„ë¡ íŠ¸ì—ì„œ ì´ ì½”ë“œ ë³´ê³  "ì§‘ì¤‘ë„ ëª¨ë¸ ì•„ì§ ì—†ìŒ" ì²˜ë¦¬í•˜ë©´ ë¨
        raise HTTPException(
            status_code=503,
            detail="Focus model not loaded (no checkpoint found).",
        )

    skel_np = np.array(input_data.skeleton, dtype=np.float32)  # (C,T,V,M)
    pred_idx, probs = predict_focus_single(skel_np)
    focus_label = FOCUS_ID_TO_LABEL.get(pred_idx, f"class_{pred_idx}")

    return FocusPredictResponse(
        focus_id=pred_idx,
        focus_label=focus_label,
        probs=probs.tolist(),
    )
